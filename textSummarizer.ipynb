{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "textSummarizer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBInEsMuEbAc"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/textSummarization/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1lnC8HVA5Ts",
        "outputId": "08e68b2f-3c81-4424-b646-4128b3ae717b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjFYIDpxC9Pw",
        "outputId": "7a2d423b-d90c-4c53-a45b-689ce2a12c09"
      },
      "source": [
        "from pickle import load\n",
        "cleanStories = load(open('/content/drive/MyDrive/textSummarization/cnn_dataset_cleaned.pkl', 'rb'))\n",
        "print('Loaded Stories %d' % len(cleanStories))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Stories 92579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHDMS1LSDzMt"
      },
      "source": [
        "# Populate stories and highlights in seperate lists(desc - description and highlights)\n",
        "desc = []\n",
        "highlights = []\n",
        "for i in range(len(cleanStories)):\n",
        "    desc.append(cleanStories[i]['story'])\n",
        "    highlights.append(cleanStories[i]['highlights'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-XneOqXgLNUH",
        "outputId": "267946bc-98c4-4bf4-de41-6aa0770f80d7"
      },
      "source": [
        "#%tensorflow_version 1.x\n",
        "!pip install tensorflow==2.1.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.1.0\n",
            "  Downloading tensorflow-2.1.0-cp37-cp37m-manylinux2010_x86_64.whl (421.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8 MB 26 kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (3.17.3)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "  Downloading tensorboard-2.1.1-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 44.8 MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (0.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.1.2)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "  Downloading tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 41.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.13.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.19.5)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.42.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (0.2.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.4.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (0.37.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (3.3.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (3.1.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.6)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (57.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==2.1.0) (1.5.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=6e24872e37d172565cf3e2132f90f7c07a19824a6cefe5f7564b02662a93873b\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.7.0\n",
            "    Uninstalling tensorflow-estimator-2.7.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.7.0\n",
            "    Uninstalling tensorboard-2.7.0:\n",
            "      Successfully uninstalled tensorboard-2.7.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.7.0\n",
            "    Uninstalling tensorflow-2.7.0:\n",
            "      Successfully uninstalled tensorflow-2.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.15.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HXPMphzhLRFp",
        "outputId": "ba2b6978-784f-4baf-82bb-868769002887"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.1.0'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0yxz31ID4i1"
      },
      "source": [
        "import numpy as np  \n",
        "import pandas as pd \n",
        "from tensorflow.keras.preprocessing.text import Tokenizer \n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords   \n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfVpal65D87Y"
      },
      "source": [
        "from attentionLayer import AttentionLayer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXiTGijTD9Ui"
      },
      "source": [
        "#Adding start and end tokens\n",
        "highlights =  list(map(lambda x:'_START_ '+ ' '.join(x) + ' _END_',highlights))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "SNkNAOkxBzlz",
        "outputId": "129a4159-39a7-427e-8711-929a158935bf"
      },
      "source": [
        "highlights[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'_START_ syrian official obama climbed to the top of the tree doesnt know how to get down obama sends a letter to the heads of the house and senate obama to seek congressional approval on military action against syria aim is to determine whether cw were used not by whom says un spokesman _END_'"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uao74F1_D9jU"
      },
      "source": [
        "nonTokDesc = desc[:]\n",
        "#reverting tokenization\n",
        "nonTokDesc = list(map(lambda x:' '.join(x),nonTokDesc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "fwmeIKzGD9zM",
        "outputId": "848cccdc-6988-4f5f-e6a1-ebef9588c538"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "textWords = []\n",
        "summaryWords = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in nonTokDesc:\n",
        "      textWords.append(len(i.split()))\n",
        "\n",
        "for i in highlights:\n",
        "      summaryWords.append(len(i.split()))\n",
        "\n",
        "df = pd.DataFrame({'text':textWords, 'summary':summaryWords})\n",
        "df.hist(bins = 30)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSx2RwuzD-BH"
      },
      "source": [
        "#Lets set our max text and highlights size for padding and further reference\n",
        "max_len_text= 350 \n",
        "max_len_summary= 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuJTwQlbD-QJ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_tr,x_val,y_tr,y_val=train_test_split(nonTokDesc,highlights,test_size=0.1,random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOBhhEieD-qK"
      },
      "source": [
        "# Tokenizer for desc data\n",
        "desc_tokenizer = Tokenizer()\n",
        "desc_tokenizer.fit_on_texts(list(x_tr))\n",
        "\n",
        "# Text to integers\n",
        "x_tr    =   desc_tokenizer.texts_to_sequences(x_tr) \n",
        "x_val   =   desc_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "# Padding \n",
        "x_tr    =   pad_sequences(x_tr,  maxlen=max_len_text, padding='post') \n",
        "x_val   =   pad_sequences(x_val, maxlen=max_len_text, padding='post')\n",
        "\n",
        "x_voc_size   =  len(desc_tokenizer.word_index) +1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5iYhHJTD-2C"
      },
      "source": [
        "# Tokenizer for highlights data\n",
        "hig_tokenizer = Tokenizer()\n",
        "hig_tokenizer.fit_on_texts(list(y_tr))\n",
        "\n",
        "# Text to integers\n",
        "y_tr    =   hig_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val   =   hig_tokenizer.texts_to_sequences(y_val) \n",
        "\n",
        "# Padding\n",
        "y_tr    =   pad_sequences(y_tr, maxlen=max_len_summary, padding='post')\n",
        "y_val   =   pad_sequences(y_val, maxlen=max_len_summary, padding='post')\n",
        "y_voc_size  =  len(hig_tokenizer.word_index) +1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "Tv47VHxyF9nG",
        "outputId": "ee1c4b62-0d44-4b2f-c73b-4d7592395ff6"
      },
      "source": [
        "pip install numpy==1.19.2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.19.2\n",
            "  Downloading numpy-1.19.2-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.5 MB 5.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.15.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.19.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b60EBzK08jvI"
      },
      "source": [
        "from attentionLayer import AttentionLayer\n",
        "from tensorflow.keras import backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HGR49flD_AM",
        "outputId": "21f8edf9-89da-439a-cf29-ef8eea985b2a"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "K.clear_session() \n",
        "latent_dim = 500\n",
        "#latent_dim = int(2/3 * (x_voc_size * 26)) cant use because of resourceExhaustedError\n",
        "\n",
        "# Encoder \n",
        "encoder_inputs = Input(shape=(max_len_text,)) \n",
        "enc_emb = Embedding(x_voc_size, latent_dim,trainable=True)(encoder_inputs) \n",
        "\n",
        "#LSTM 1 \n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \n",
        "\n",
        "#LSTM 2 \n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
        "\n",
        "#LSTM 3 \n",
        "encoder_lstm3 = LSTM(latent_dim, return_state=True, return_sequences=True) \n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2) \n",
        "\n",
        "# Decoder \n",
        "decoder_inputs = Input(shape=(None,)) \n",
        "dec_emb_layer = Embedding(y_voc_size, latent_dim,trainable=True) \n",
        "dec_emb = dec_emb_layer(decoder_inputs) \n",
        "\n",
        "#LSTM using encoder_states as initial state\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) \n",
        "\n",
        "#Attention Layer\n",
        "attn_layer = AttentionLayer(name='attention_layer') \n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n",
        "\n",
        "# Concat attention output and decoder LSTM output \n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "#Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax')) \n",
        "decoder_outputs = decoder_dense(decoder_concat_input) \n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 350)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 350, 500)     152135500   input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 350, 500), ( 2002000     embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 350, 500), ( 2002000     lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 500)    41012500    input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 350, 500), ( 2002000     lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 500),  2002000     embedding_1[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer ((None, None, 500),  500500      lstm_2[0][0]                     \n",
            "                                                                 lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 1000)   0           lstm_3[0][0]                     \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 82025)  82107025    concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 283,763,525\n",
            "Trainable params: 283,763,525\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hT0meJ-_D_Yu"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy') #PLSA/LDA datamining,topic mining"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sXdkk9mD_jm"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4_jWyLRD_7Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f15c813-561e-4264-e85d-a0b3b68e49fa"
      },
      "source": [
        "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=1,batch_size=50, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 83321 samples, validate on 9258 samples\n",
            "83321/83321 [==============================] - 2750s 33ms/sample - loss: 6.1499 - val_loss: 6.0695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJIKqk4KEAIL"
      },
      "source": [
        "# save as JSON\n",
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LR8IUFIBDiP"
      },
      "source": [
        "model.save('/content/drive/MyDrive/textSummarization/EnDeAt_1.h5')  # creates a HDF5 file 'my_model.h5'\n",
        "#del model  # deletes the existing model\n",
        "\n",
        "    # returns a compiled model\n",
        "    # identical to the previous one\n",
        "#model = load_model('my_model.h5')\n",
        "#json_string = model.to_json()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "UKp6tDpDFFL6",
        "outputId": "fe18f481-0b38-475e-b587-2418c42adf07"
      },
      "source": [
        "#Since we are using tensorflow version below 2.5 here we have to downgrade h5 to make it compatible \n",
        "!pip install 'h5py==2.10.0'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n",
            "Installing collected packages: h5py\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "Successfully installed h5py-2.10.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "h5py"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBxntm7mchSe"
      },
      "source": [
        "model = load_model('/content/drive/MyDrive/textSummarization/EnDeAt_1.h5',custom_objects={\"AttentionLayer\": AttentionLayer})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "Qq9TPTtg9_UU",
        "outputId": "7eefde6f-1cf5-4747-face-34394bdda5e0"
      },
      "source": [
        "json_string"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'{\"class_name\": \"Model\", \"config\": {\"name\": \"model\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 350], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"input_1\"}, \"name\": \"input_1\", \"inbound_nodes\": []}, {\"class_name\": \"Embedding\", \"config\": {\"name\": \"embedding\", \"trainable\": true, \"batch_input_shape\": [null, null], \"dtype\": \"float32\", \"input_dim\": 304271, \"output_dim\": 500, \"embeddings_initializer\": {\"class_name\": \"RandomUniform\", \"config\": {\"minval\": -0.05, \"maxval\": 0.05, \"seed\": null}}, \"embeddings_regularizer\": null, \"activity_regularizer\": null, \"embeddings_constraint\": null, \"mask_zero\": false, \"input_length\": null}, \"name\": \"embedding\", \"inbound_nodes\": [[[\"input_1\", 0, 0, {}]]]}, {\"class_name\": \"LSTM\", \"config\": {\"name\": \"lstm\", \"trainable\": true, \"dtype\": \"float32\", \"return_sequences\": true, \"return_state\": true, \"go_backwards\": false, \"stateful\": false, \"unroll\": false, \"time_major\": false, \"units\": 500, \"activation\": \"tanh\", \"recurrent_activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"recurrent_initializer\": {\"class_name\": \"Orthogonal\", \"config\": {\"gain\": 1.0, \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"unit_forget_bias\": true, \"kernel_regularizer\": null, \"recurrent_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"recurrent_constraint\": null, \"bias_constraint\": null, \"dropout\": 0.0, \"recurrent_dropout\": 0.0, \"implementation\": 2}, \"name\": \"lstm\", \"inbound_nodes\": [[[\"embedding\", 0, 0, {}]]]}, {\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, null], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"input_2\"}, \"name\": \"input_2\", \"inbound_nodes\": []}, {\"class_name\": \"LSTM\", \"config\": {\"name\": \"lstm_1\", \"trainable\": true, \"dtype\": \"float32\", \"return_sequences\": true, \"return_state\": true, \"go_backwards\": false, \"stateful\": false, \"unroll\": false, \"time_major\": false, \"units\": 500, \"activation\": \"tanh\", \"recurrent_activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"recurrent_initializer\": {\"class_name\": \"Orthogonal\", \"config\": {\"gain\": 1.0, \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"unit_forget_bias\": true, \"kernel_regularizer\": null, \"recurrent_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"recurrent_constraint\": null, \"bias_constraint\": null, \"dropout\": 0.0, \"recurrent_dropout\": 0.0, \"implementation\": 2}, \"name\": \"lstm_1\", \"inbound_nodes\": [[[\"lstm\", 0, 0, {}]]]}, {\"class_name\": \"Embedding\", \"config\": {\"name\": \"embedding_1\", \"trainable\": true, \"batch_input_shape\": [null, null], \"dtype\": \"float32\", \"input_dim\": 82025, \"output_dim\": 500, \"embeddings_initializer\": {\"class_name\": \"RandomUniform\", \"config\": {\"minval\": -0.05, \"maxval\": 0.05, \"seed\": null}}, \"embeddings_regularizer\": null, \"activity_regularizer\": null, \"embeddings_constraint\": null, \"mask_zero\": false, \"input_length\": null}, \"name\": \"embedding_1\", \"inbound_nodes\": [[[\"input_2\", 0, 0, {}]]]}, {\"class_name\": \"LSTM\", \"config\": {\"name\": \"lstm_2\", \"trainable\": true, \"dtype\": \"float32\", \"return_sequences\": true, \"return_state\": true, \"go_backwards\": false, \"stateful\": false, \"unroll\": false, \"time_major\": false, \"units\": 500, \"activation\": \"tanh\", \"recurrent_activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"recurrent_initializer\": {\"class_name\": \"Orthogonal\", \"config\": {\"gain\": 1.0, \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"unit_forget_bias\": true, \"kernel_regularizer\": null, \"recurrent_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"recurrent_constraint\": null, \"bias_constraint\": null, \"dropout\": 0.0, \"recurrent_dropout\": 0.0, \"implementation\": 2}, \"name\": \"lstm_2\", \"inbound_nodes\": [[[\"lstm_1\", 0, 0, {}]]]}, {\"class_name\": \"LSTM\", \"config\": {\"name\": \"lstm_3\", \"trainable\": true, \"dtype\": \"float32\", \"return_sequences\": true, \"return_state\": true, \"go_backwards\": false, \"stateful\": false, \"unroll\": false, \"time_major\": false, \"units\": 500, \"activation\": \"tanh\", \"recurrent_activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"recurrent_initializer\": {\"class_name\": \"Orthogonal\", \"config\": {\"gain\": 1.0, \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"unit_forget_bias\": true, \"kernel_regularizer\": null, \"recurrent_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"recurrent_constraint\": null, \"bias_constraint\": null, \"dropout\": 0.0, \"recurrent_dropout\": 0.0, \"implementation\": 2}, \"name\": \"lstm_3\", \"inbound_nodes\": [[[\"embedding_1\", 0, 0, {}], [\"lstm_2\", 0, 1, {}], [\"lstm_2\", 0, 2, {}]]]}, {\"class_name\": \"AttentionLayer\", \"config\": {\"name\": \"attention_layer\", \"trainable\": true, \"dtype\": \"float32\"}, \"name\": \"attention_layer\", \"inbound_nodes\": [[[\"lstm_2\", 0, 0, {}], [\"lstm_3\", 0, 0, {}]]]}, {\"class_name\": \"Concatenate\", \"config\": {\"name\": \"concat_layer\", \"trainable\": true, \"dtype\": \"float32\", \"axis\": -1}, \"name\": \"concat_layer\", \"inbound_nodes\": [[[\"lstm_3\", 0, 0, {}], [\"attention_layer\", 0, 0, {}]]]}, {\"class_name\": \"TimeDistributed\", \"config\": {\"name\": \"time_distributed\", \"trainable\": true, \"dtype\": \"float32\", \"layer\": {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 82025, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}}, \"name\": \"time_distributed\", \"inbound_nodes\": [[[\"concat_layer\", 0, 0, {}]]]}], \"input_layers\": [[\"input_1\", 0, 0], [\"input_2\", 0, 0]], \"output_layers\": [[\"time_distributed\", 0, 0]]}, \"keras_version\": \"2.2.4-tf\", \"backend\": \"tensorflow\"}'"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCbT9NIT_NoK"
      },
      "source": [
        "reverse_target_word_index=hig_tokenizer.index_word \n",
        "reverse_source_word_index=desc_tokenizer.index_word \n",
        "target_word_index=hig_tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAiDopxF_N4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "fd341b60-f68c-48ff-8682-cf66409085df"
      },
      "source": [
        "# encoder inference\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# decoder inference\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_len_text,latent_dim))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "#attention inference\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "[decoder_outputs2] + [state_h2, state_c2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-ed75e6c7be0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# encoder inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mencoder_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# decoder inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Below tensors will hold the states of the previous time step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'encoder_inputs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrMGCXPp_OAV"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "\n",
        "    # Chose the 'start' word as the first word of the target sequence\n",
        "    target_seq[0, 0] = target_word_index['start']\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "\n",
        "        if(sampled_token!='end'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "            # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'end' or len(decoded_sentence.split()) >= (max_len_summary-1)):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYxxEny0_OC4"
      },
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if((i!=0 and i!=target_word_index['start']) and i!=target_word_index['end']):\n",
        "        newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if(i!=0):\n",
        "        newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fy6cJi8_lOy",
        "outputId": "513e6719-6e5f-4cb9-ef55-2c89c7d51593"
      },
      "source": [
        "x_val[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1415,  8021,     1,    56,  1168,    35,   863, 12949,     2,\n",
              "         942,    11,  1555,  3763,  1726,  6421,     4,    67,   242,\n",
              "           7,    60,    23,  6898,     2,     5,   671,  1927,  3598,\n",
              "         125,   154,  7251,     4,   967,     1, 22372,  2595, 14984,\n",
              "          10, 14984,    10,    18,   338,  9902,    14,    31,   248,\n",
              "         347,  6491,     4,    67,  1039,    97,   325,     1,   279,\n",
              "           4,     7,   493,     2,     1,   823,  8335,     3,     1,\n",
              "       71376, 56386,    14,   892, 13232,  1039,     6,  7499,  3471,\n",
              "           4, 87040,  1867,  1890, 15252,    39,    64,     3,   113,\n",
              "        2260,  8021,   106,   320,   406,  2260,    62, 13246,    64,\n",
              "           3,   113,  8021,    21,  4188,   613,     4,    78,    28,\n",
              "        1347,     1,   745,  2692,    16,    54,    37,    52,   342,\n",
              "           5,   399, 82887,    64,    21,     8,  8369,     8, 77460,\n",
              "          64,    21,   932,     8,   613,     4,    61,    92,    35,\n",
              "         126,   772,    11,     1,  5852,  2051,   704, 14984,    10,\n",
              "        1727, 23809,    21,  5852,  2965,     3,  9682,  4713,    13,\n",
              "          10,    20,  2143,     1,    56,  1168,    83,    23,    16,\n",
              "        1789,    16,   431, 14984,    10,    24,   272,    68,   216,\n",
              "         140,  5624,  1977,    14,  1090,     1,  1727, 23809,    61,\n",
              "          92,    35,    28,    23,   852,   610,    15,    12,  2114,\n",
              "         205,     7,     1, 14928,   207,  1727, 23809,     6,    36,\n",
              "         288,     1,   613,    34,    28,  2636,     4,   830,   312,\n",
              "          67,  2908,     3,  8021,    34,   207,    77,   217,   298,\n",
              "       23165,     9,     7,     5,   249,     3,     1, 14928,    34,\n",
              "        1428, 18110,   175,     1,  2986,     6,   194,    17,     1,\n",
              "          65, 18110,  6445,  8021,    44,  5786,  8021,     5,  1325,\n",
              "         793,   706,    10,    17,     5,   624,   873,     3,     1,\n",
              "        1325,     5, 48970,  4325,    12,  5603,   130,     1,   873,\n",
              "           1,  1325,    10,    31,   371,   161,     7,    17,   255,\n",
              "          66,  8021,    72,    25,    34,   580,  4276,    26,     1,\n",
              "       14928,     4,    19,    28,    43,   161,     6,     1,  8589,\n",
              "           1, 14928,   229,   366,   791,    48,     1,   415,     1,\n",
              "        3381,  5852,     5,  2153,  1391,     3,  2051,    22,  1089,\n",
              "       10954,    24,    15,    27,  6193,    43, 60336,    64,  2250,\n",
              "        2051,   139,    16,  7853, 44406,     4,  1916,    11,  4888,\n",
              "           1,  3381,    27,  3958,     1,   704,    16,    15,   124,\n",
              "          48,     5,  6480,  1485,  6441,     6,   810,    47,    15,\n",
              "        5852,  1785,   559,  7705,     3, 18435,     4, 35154,    11,\n",
              "         728,  1089,   379,     1,   727,   164,    11,  4446],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mtpb2F-y_OFw"
      },
      "source": [
        "def valPredict(i):\n",
        "  print(\"Review:\",seq2text(x_val[i]))\n",
        "  print(\"Original summary:\",seq2summary(y_val[i]))\n",
        "  print(\"Predicted summary:\",decode_sequence(x_val[i].reshape(1,max_len_text)))\n",
        "  print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "-pEjpLo7DfRr",
        "outputId": "e540f93c-9d0c-4637-d2da-de15ee5e79a3"
      },
      "source": [
        "valPredict(24)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-fa204ad0e0a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalPredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-29-c73d9e48c6d7>\u001b[0m in \u001b[0;36mvalPredict\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvalPredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Review:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq2text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;31m#print(\"Original summary:\",seq2summary(y_val[i]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted summary:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_len_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-085da0858a1b>\u001b[0m in \u001b[0;36mseq2text\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mseq2text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnewString\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_seq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m       \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mnewString\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewString\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mreverse_source_word_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLr2HePiCky0",
        "outputId": "cb6a20b1-d0de-4386-c2fa-2304f4548be4"
      },
      "source": [
        "x_val[24]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3962,  5529,   152,  3739, 13578, 41216,   794,    97,     5,\n",
              "         549,   209,    24,  1335,   892,     3,  5347,     5,  3012,\n",
              "         426,     2,  4744,   554,     4, 11371,   470,     7, 11107,\n",
              "          22,     1,   624,   693,     3, 13404,  7126,     5,  1872,\n",
              "        1113,     2,  1893,     5,  3719, 11371,   929,    53,    12,\n",
              "        1138,    48,     1,  6533,  1206,  1630,     5,  1360,   490,\n",
              "         141,     3,     5,  1226,     2,     5,  6740,    24,    18,\n",
              "        1079,   261,     8,    42,    65,    97,  3495,     5,  3012,\n",
              "           1,   174,    12, 13561,     8,   751,   799,   865,   459,\n",
              "        1970,   830,    34,   453,     8,   487,     7,  5529,  1801,\n",
              "           5,  2131,   131,    14,  4952,     6,   624,    47,    30,\n",
              "         517, 13404,   152,  3739,     8,  3245,     3,  1552,  1116,\n",
              "        1077,     5,  3719, 11371,   929,    12,   304,    48, 13578,\n",
              "       41216,   572,   332,   405,     9, 17706,  1455,  1206,  1630,\n",
              "           5,   490,    55,     3,     1,  1226,     6,     5,  1360,\n",
              "        1406,   292,   100,  1403,     2,    23, 20495,    55,  3910,\n",
              "        1811,   980,    45,     3,     1,  1077,     6,     1, 14379,\n",
              "        3245,    12, 23534,    57,   294,    16, 11877,    44, 17346,\n",
              "           5,  1970,  4497,    10,     1,  1872,  2174,     6,   158,\n",
              "         209,     7,     1,   490,  1098,   124,    28,   845,     1,\n",
              "        8252,     8,     5,  3719, 11371,   929,  1455,    12,  3465,\n",
              "           6,   158,    26,  1079,  9636, 22035,    32,     9,    57,\n",
              "       13404,   467,     1,   799,   865,   459,   667,   467,    27,\n",
              "         344,     2,  1685,    59,  5529,    35,    23,   734,    14,\n",
              "       11371,     8,     1,  6297,   288,     1,  1872,    83,  1685,\n",
              "           2,   115,    15,     5,  3719,   174,   127,   830,    10,\n",
              "          15,   978,    29,  1431,     6,  1098,     2,     5, 27497,\n",
              "         476,  7126,    15,    83,    57,    23,  5968,    16,    68,\n",
              "           5,  6740,    84,     3,     1,  1525,     3,     1,   502,\n",
              "        1970,  5115,   261,     8,     5,  3719,   929,   108,  5529,\n",
              "          24,    18,  1656,  2783,     7,     1, 36085,    12,     5,\n",
              "       26152, 11125,  5529, 36085,     5,  7662, 11125,    28,     5,\n",
              "        3719,  1656,  2783,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR2TJvszCc15"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_MYanQEDHyT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}